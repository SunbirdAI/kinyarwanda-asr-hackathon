{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de2004-560f-446e-bfa6-07af53f7349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install jiwer  datasets librosa pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f1648-80ab-42bc-877e-61c5143b12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jiwer \n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from datasets import load_dataset, Dataset, Audio, Value, Features\n",
    "import gc\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29fa96-160b-417e-8d8c-b85b6fed6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for better performance\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# Optimize pandas and numpy\n",
    "pd.set_option('mode.copy_on_write', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01658089-7f2a-4e4a-840c-f67a0e46656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.set_threshold(100, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8696a76-29b4-49d5-8982-a21f0bcc9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized features definitions\n",
    "features = Features({\n",
    "    \"id\": Value(\"string\"),\n",
    "    \"audio\": Audio(), \n",
    "    \"audio_language\": Value(\"string\"),                   \n",
    "    \"text\": Value(\"string\"),\n",
    "    \"transcription\": Value(\"string\"),\n",
    "    \"wer\": Value(\"float32\"),                       \n",
    "    \"wer_range\": Value(\"string\"),                 \n",
    "    \"prompt\": Value(\"string\"),   \n",
    "    \"duration\": Value(\"float32\"),        \n",
    "    \"speaker_id\": Value(\"string\")\n",
    "})\n",
    "\n",
    "features1 = Features({\n",
    "    \"id\": Value(\"string\"),\n",
    "    \"audio\": Audio(), \n",
    "    \"audio_language\": Value(\"string\"),                   \n",
    "    \"text\": Value(\"string\"),              \n",
    "    \"prompt\": Value(\"string\"),   \n",
    "    \"duration\": Value(\"float32\"),        \n",
    "    \"speaker_id\": Value(\"string\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae788c05-3f52-44f8-85f5-c3d3635af4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/kin/whisper_transcriptions.csv\"\n",
    "HF_TOKEN = \"\" #huggingface token or you can login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed024279",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07e5a9-c7a7-4fd5-a066-401892eea841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file, \n",
    "                 dtype={'id': 'string', 'transcription': 'string'},\n",
    "                 engine='c')\n",
    "df = df.set_index('id')\n",
    "df['id'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d8438-0c17-4195-bee0-545633483225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = df.to_dict('index')\n",
    "df_ids = set(df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480415f4-e7a4-4a3a-994c-881e79d4d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ca0e5-f2fe-4d30-877d-81bc7a6f2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CSV loaded in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59962a99-6d86-4d02-9c66-b0d51615e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "start_time = time.time()\n",
    "\n",
    "dataset = load_dataset('jq/kinyarwanda-speech-hackathon', \n",
    "                      split='train', \n",
    "                      token=HF_TOKEN,\n",
    "                      num_proc=min(32, mp.cpu_count())) \n",
    "print(f\"Dataset loaded in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca53872-76be-4fbe-a7b1-83c9e5e7f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_df_ids_batch(examples):\n",
    "    \"\"\"Filter function that works on batches - much more memory efficient\"\"\"\n",
    "    keep_mask = [example_id in df_ids for example_id in examples['id']]\n",
    "    return keep_mask\n",
    "\n",
    "print(\"Filtering with memory-efficient batching...\")\n",
    "start_time = time.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518e827-f003-42a5-9030-490059d1f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = dataset.filter(\n",
    "    filter_by_df_ids_batch, \n",
    "    batched=True,\n",
    "    batch_size=2000,  \n",
    "    num_proc=1,       # SINGLE PROCESS - no memory multiplication\n",
    "    desc=\"Filtering dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3c6fb-c35c-425f-bc3f-39b863f11a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer_batch(examples):\n",
    "    \"\"\"\n",
    "    Calculate WER for a batch of examples - much faster than individual processing\n",
    "    \"\"\"\n",
    "    batch_size = len(examples['id'])\n",
    "    wers = []\n",
    "    wer_ranges = []\n",
    "    transcriptions = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        try:\n",
    "            example_id = examples['id'][i]\n",
    "            \n",
    "            # Fast dictionary lookup\n",
    "            if example_id in df_dict:\n",
    "                row = df_dict[example_id]\n",
    "                transcription = row.get('transcription', '')\n",
    "            else:\n",
    "                transcription = examples.get('transcription', [''])[i] if 'transcription' in examples else ''\n",
    "            \n",
    "            transcriptions.append(transcription)\n",
    "            \n",
    "            reference = examples.get('text', [''])[i]\n",
    "            \n",
    "            if not reference or not transcription:\n",
    "                wer = float('inf')\n",
    "            else:\n",
    "                wer = jiwer.wer(reference.lower(), transcription.lower())\n",
    "            \n",
    "            wers.append(wer)\n",
    "            \n",
    "            # Vectorized WER range calculation its not necessary\n",
    "            if wer <= 0.10:\n",
    "                wer_range = \"0–0.10\"\n",
    "            elif wer <= 0.20:\n",
    "                wer_range = \"0.11–0.20\"\n",
    "            elif wer <= 0.30:\n",
    "                wer_range = \"0.21–0.30\"\n",
    "            elif wer <= 0.40:\n",
    "                wer_range = \"0.31–0.40\"\n",
    "            elif wer <= 0.50:\n",
    "                wer_range = \"0.41–0.50\"\n",
    "            elif wer <= 0.60:\n",
    "                wer_range = \"0.51-0.60\"\n",
    "            elif wer <= 0.70:\n",
    "                wer_range = \"0.61-0.70\"\n",
    "            elif wer <= 0.80:\n",
    "                wer_range = \"0.71-0.80\"\n",
    "            elif wer <= 0.90:\n",
    "                wer_range = \"0.81-0.90\"\n",
    "            elif wer <= 1.00:\n",
    "                wer_range = \"0.91-1.00\"\n",
    "            else:\n",
    "                wer_range = \">1.00\"\n",
    "                \n",
    "            wer_ranges.append(wer_range)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {examples['id'][i]}: {e}\")\n",
    "            wers.append(float('inf'))\n",
    "            wer_ranges.append(\">1.00\")\n",
    "            transcriptions.append('')\n",
    "    \n",
    "    # Return the batch with new fields\n",
    "    examples['wer'] = wers\n",
    "    examples['wer_range'] = wer_ranges\n",
    "    examples['transcription'] = transcriptions\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55674dfd-a7a9-4a69-ab54-eced2c270e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating WER with batch processing...\")\n",
    "start_time = time.time()\n",
    "\n",
    "batch_size = 500  # Adjust based on memory\n",
    "num_proc = min(32, mp.cpu_count())  # Balance between speed and memory\n",
    "\n",
    "ds_with_wer = filtered_ds.map(\n",
    "    calculate_wer_batch,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=num_proc,\n",
    "    desc=\"Calculating WER\"\n",
    ")\n",
    "\n",
    "print(f\"WER calculation completed in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d299ced-dabd-476a-8636-dc0aad073507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting to pandas...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result_df = ds_with_wer.to_pandas()\n",
    "\n",
    "print(f\"Pandas conversion completed in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafad15-f6f6-42b3-8a84-a1fd0cd66e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtering and preparing final dataset...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use query for faster filtering\n",
    "res_df = result_df.query('wer < 0.90')[['id', 'audio', 'audio_language', 'text', 'prompt', 'duration', 'speaker_id']]\n",
    "\n",
    "print(f\"Final filtering completed in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"Final dataset size: {len(res_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3355e-6827-44a2-a93a-d7fd1393e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating and uploading datasets...\")\n",
    "start_time = time.time()\n",
    "\n",
    "cleaned_dataset = Dataset.from_pandas(res_df, preserve_index=False, features=features1)\n",
    "full_dataset = Dataset.from_pandas(result_df, preserve_index=False, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518873ee-460a-48e7-a023-39048ab55b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.push_to_hub(\n",
    "    \"evie-8/kinyarwanda-speech-hackathon\",  \n",
    "    config_name='train_cleaned',\n",
    "    split=\"train\", \n",
    "    private=True, \n",
    "    token=HF_TOKEN,\n",
    "    max_shard_size=\"500MB\"\n",
    ")\n",
    "\n",
    "full_dataset.push_to_hub(\n",
    "    \"evie-8/kinyarwanda-hackathon\", \n",
    "    split=\"train\", \n",
    "    token=HF_TOKEN,\n",
    "    max_shard_size=\"500MB\"\n",
    ")\n",
    "\n",
    "print(f\"Upload completed in {time.time() - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
