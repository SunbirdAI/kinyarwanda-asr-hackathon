{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d407595a-8008-496a-a349-a76797380cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Union, List, Dict, Any\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "import datasets\n",
    "import numpy as np\n",
    "import yaml\n",
    "import evaluate\n",
    "import salt.dataset\n",
    "import salt.metrics\n",
    "import salt.constants\n",
    "from salt.utils import DataCollatorCTCWithPadding as dcwp\n",
    "import huggingface_hub\n",
    "import peft\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d44c626-ae85-466c-b9e3-cb0313ceea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881b669657a74fd989f02ab8ca9655d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {'pretrained_model': 'jq/whisper-large-v3-kin'}\n",
    "#config = {'pretrained_model': 'jq/whisper-large-v3-kin-nyn-lug-xog'}\n",
    "feature_extractor = transformers.WhisperFeatureExtractor.from_pretrained(\n",
    "    config['pretrained_model'])\n",
    "processor = transformers.WhisperProcessor.from_pretrained(\n",
    "    config['pretrained_model'],\n",
    "    language=processor.tokenizer.decode(salt.constants.SALT_LANGUAGE_TOKENS_WHISPER['kin']),\n",
    "    task=\"transcribe\")\n",
    "model = transformers.WhisperForConditionalGeneration.from_pretrained(\n",
    "    config['pretrained_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "caf748a9-12c9-482c-8d96-392a8f573ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5390175-9b93-4e31-a2a2-57e75db296d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "69e5a098-c2f4-4bfc-a19b-b9c4788d0d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378385f5a0954277a830a6b98b4a514d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd63314a4a014a1eadfe0b745e35099b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_full_test_set = False\n",
    "\n",
    "if predict_full_test_set:\n",
    "    test_ds = datasets.load_dataset('jq/kinyarwanda-speech-hackathon', split='test')\n",
    "else:\n",
    "    test_ds = datasets.load_dataset('jq/kinyarwanda-speech-hackathon', split='dev_test[:300]')\n",
    "    \n",
    "test_ds = test_ds.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "19945191-c72e-427f-95f4-3441f5e6a304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979ed40235d84e7bb3e6a14f416aa7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ids = []\n",
    "test_transcriptions = []\n",
    "test_labels = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_ds))):   \n",
    "    example = test_ds[i]\n",
    "    input_features = processor(\n",
    "        example[\"audio\"][\"array\"], sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "    input_features = input_features.to('cuda')\n",
    "\n",
    "    prompt_ids = processor.tokenizer.get_prompt_ids(example['prompt'],\n",
    "        return_tensors='pt',\n",
    "    ).to('cuda')\n",
    "    \n",
    "    predicted_ids = model.generate(\n",
    "        input_features,\n",
    "        #num_beams=5,\n",
    "        #do_sample=True,\n",
    "        max_length=400,\n",
    "        temperature=0.01,\n",
    "        language=processor.tokenizer.decode(salt.constants.SALT_LANGUAGE_TOKENS_WHISPER['kin']),\n",
    "        #forced_decoder_ids=[[0,50258],[1, 50350]],\n",
    "    )\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    if not predict_full_test_set:\n",
    "        test_labels.append(example['text'])\n",
    "\n",
    "    test_transcriptions.append(transcription)\n",
    "    test_ids.append(example['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "118dade5-a4dc-4e47-b406-93857d560f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 0.100\n",
      "Character Error Rate (CER): 0.027\n",
      "Score: 0.944\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def strip_punctuation(text):\n",
    "    # Create a translation table to remove all punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "    \n",
    "def normalise(texts):\n",
    "    return [strip_punctuation(t.lower()) for t in texts]\n",
    "    \n",
    "if not predict_full_test_set:\n",
    "    total_wer = jiwer.wer(normalise(test_labels), normalise(test_transcriptions))\n",
    "    total_cer = jiwer.cer(normalise(test_labels), normalise(test_transcriptions))\n",
    "    score = 1 - (0.6 * total_cer + 0.4 * total_wer)\n",
    "    \n",
    "    print(f\"Word Error Rate (WER): {total_wer:.3f}\")\n",
    "    print(f\"Character Error Rate (CER): {total_cer:.3f}\")\n",
    "    print(f\"Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9ce34357-5e64-47dc-91b5-7b186339143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json') as f:\n",
    "    test_metadata = json.load(f)\n",
    "\n",
    "test_keys = test_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2aa0fde2-a44a-42cb-824c-1e41ed246b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for i, pred in zip(test_ids, test_transcriptions):\n",
    "    predictions[i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2d02cf27-f498-49ed-af50-6d3f6513846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def strip_punctuation(text):\n",
    "    # Create a translation table to remove all punctuation\n",
    "    punctuation = '!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    translator = str.maketrans('', '', punctuation)\n",
    "    return text.translate(translator)\n",
    "    \n",
    "with open('submission.csv', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write('id,transcription\\n')\n",
    "    for k in test_keys:\n",
    "        pred = predictions.get(k)\n",
    "        if not pred:\n",
    "            print('No prediction for key ', k)\n",
    "            f.write(f\"{k},a\\n\")\n",
    "        else:\n",
    "            normalised_pred = strip_punctuation(pred.lower())\n",
    "            f.write(f\"{k},{normalised_pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3c29127b-c965-4073-ab4d-90a160098296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9266 submission.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "031726c4-0817-4c18-8f51-cb26641439ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,transcription\n",
      "4ibA9OLWZTajRbwnWjjY,ndabona umugabo uri kuri uhagaze wambaye kasike na jire akaba ashobora kuba atwara ibintu handitseho ngo kashi\n",
      "ZarC9zz753YnLnE98mpK,pisine ku ruhande rwayo hari udutebe dutwikiriye n'imitaka tubiri ku rundi ruhande naho hakaba hari akandi gatebe konyine hirya hakaba udutebe tundi hari n'imitaka itwikiriye hirya yaho hakaba hari inzu iri kubakwa itari yuzura\n",
      "1ai3w0iU2yUOeUtLoTSX,ubwishingizi ni ingenzi cyane kubera ko budufasha kandi ntaho batageze bahageze amashami yabo hano ni muri rusizi nk'iki kirango nk'uko kibigaragaza mu ibara ry'ubururu amagambo yandikishije umweru ndetse n'umuhondo ubona ko rero ushobora kuza nawe ugatanga ikibazo cyawe bakakugoboka\n",
      "IQFsYcsFTsGlnqftc8jg,imodoka ihagaze iri mu ibara ritukura iriho ibirango byamamaza isoko rikorera kuri murandasi hariho nimero zabo za telefone ngendanwa ndetse n'ahandi hose ushobora kubabona\n",
      "Sd3umUI1wjqp5z5poHe6,ahantu bacururiza amata hari ameza ya purasitike imwe iteretseho ishage n'umufuniko indi iriho isiniya hirya hari akamashini k'amata munsi hari indobo ku ruhande hari umuntu uhahagaze hari etajeri y'ibirahure hariho isiniya iriho amagi munsi harimo anvelope inyuma muri etajeri harimo fanta amata y'inyange na ji hari n'amakarito yanditseho inyange\n",
      "vS4iVNNwWu14ht4g1ylq,abagabo batatu bahagaze umwe yambaye ijire y'umuhondo undi ishati y'umweru ipantaro ya shokora bareba imbere\n",
      "1iPnwM0vymgg8uwyxO3D,ubu ni uburyo bwo gukoresha amafaranga y'amanyamahanga aya ngaya ni amafaranga y'amanyamahanga tureba amahanga atandukanye ushobora kuzana ayo mu mahanga y'igihugu kimwe bakaguhereza ayo mu kindi gihugu bitewe n'icyo ugiye kujyamo cyangwa se aho ugiye kuyakoresha cyangwa ukazana amanyarwanda na bwo bakaguhereza ayo mu bihugu bigiye bitandukanye\n",
      "8oI58vZCLsQ6ldzMta02,urubuga wakwifashisha uri ku murongo rwitwa bayanse rugizwe n'itsinda ry'abantu ibihumbi bine magana cyenda wakwifashisha ushaka kugura cyangwa kugurisha\n",
      "Gq9naAwzv9QA84uxg3A3,akazu gafite amabara y'umutuku akaba ari akazu gatanga serivisi za mobayiro mani handitseho eyateri ku ruhande hariho umuhanda ndetse hakaba harimo haracamo n'imodoka hirya hari abantu benshi bamwe baricaye abandi barahagaze\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8878068-9d28-41f6-a4ab-6de5fa657ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
